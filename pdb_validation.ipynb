{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For verifying that PDB files present are loadable via all platforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supressing annoying warnings (!must be done first!)\n",
    "import warnings\n",
    "\n",
    "# General\n",
    "import re\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from shutil import copyfile\n",
    "\n",
    "# Logging\n",
    "import logging\n",
    "from rich.progress import Progress, track\n",
    "\n",
    "# Cheminformatics\n",
    "from rdkit import Chem\n",
    "from openmm.app import PDBFile\n",
    "from openff.toolkit import Topology\n",
    "\n",
    "# Custom\n",
    "from polysaccharide2.genutils.fileutils.filetree import clear_dir\n",
    "from polysaccharide2.monomers.repr import MonomerGroup\n",
    "from polysaccharide2.residues.partition import partition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correcting PDB residue name spacing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_PDB_resname_pos(pdb_block : str, delimiter : str='\\n', res_idx : int=17-1) -> str:\n",
    "    '''For correcting spacing issues with PDB residue names'''\n",
    "    lines = []\n",
    "    for line in pdb_block.split(delimiter):\n",
    "        if re.match('HETATM|ATOM', line) and (line[res_idx] != ' '):\n",
    "            lines.append(line[:res_idx] + ' ' + line[res_idx:])\n",
    "        else:\n",
    "            lines.append(line)\n",
    "\n",
    "    return delimiter.join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdb_dir  = Path('polymer_examples/compatible_pdbs')\n",
    "mono_dir = Path('polymer_examples/monomer_generation/json_files/')\n",
    "\n",
    "clean_pdb_dir = Path('cleaned_pdbs')\n",
    "clean_pdb_dir.mkdir(exist_ok=True)\n",
    "clear_dir(clean_pdb_dir)\n",
    "\n",
    "SQUARE_RE = re.compile(r's\\d+$')\n",
    "pdb_subdirs_valid = [\n",
    "    pdb_subdir\n",
    "        for pdb_subdir in pdb_dir.iterdir()\n",
    "            if pdb_subdir.is_dir()\n",
    "]\n",
    "\n",
    "records = {}\n",
    "with Progress() as progress:\n",
    "    warnings.filterwarnings('ignore', category=DeprecationWarning) # doesn't actually seem to do anything about mbuild warnings\n",
    "    task1  = progress.add_task('Polymer Type', total=len(pdb_subdirs_valid))\n",
    "    task2  = progress.add_task('Molecule') # totals will vary by type\n",
    "    STATUS = progress.add_task('Status') # totals will vary by type\n",
    "\n",
    "    for pdb_subdir in pdb_subdirs_valid:\n",
    "        poly_type = pdb_subdir.name\n",
    "        progress.update(task1, description=f'Polymer Type : {poly_type}')\n",
    "\n",
    "        # generate copy directories for polymer type \n",
    "        pdb_out_subdir = clean_pdb_dir / poly_type\n",
    "        pdb_out_subdir.mkdir(exist_ok=True)\n",
    "\n",
    "        # locate all square-free PDBs present\n",
    "        pdb_paths_valid = [\n",
    "            pdb_path\n",
    "                for pdb_path in pdb_subdir.iterdir()\n",
    "                    if not re.search(SQUARE_RE, pdb_path.stem) # ignore squared patterns\n",
    "        ]\n",
    "\n",
    "        progress.reset(task2, total=len(pdb_paths_valid)) # clear progress on secondary bar, set length to new pdb count\n",
    "        for pdb_path in pdb_paths_valid:\n",
    "            mol_name = pdb_path.stem\n",
    "            progress.update(task2, description=f'Molecule : {mol_name}')\n",
    "            progress.update(STATUS, description='Waiting...')\n",
    "\n",
    "            with pdb_path.open('r') as file:\n",
    "                pdb_block_orig = file.read()\n",
    "            pdb_block_shifted = adjust_PDB_resname_pos(pdb_block_orig)\n",
    "\n",
    "            steps = {\n",
    "                ('Worked the first time! Continuing...', 'INITIALLY FAILED, attempting PDB Residue Name shift' ): pdb_block_orig,\n",
    "                ('Residue name shift fixed it! Continuing...', 'FAILED AGAIN, issue is something deeper' ): pdb_block_shifted\n",
    "            }\n",
    "\n",
    "            for (succ_msg, fail_msg), pdb_block in steps.items():\n",
    "            # initial file load to check for successful RDKit load\n",
    "                rdmol = Chem.MolFromPDBBlock(pdb_block)\n",
    "                if rdmol is None:\n",
    "                    continue # when completely invalid, proceed with loop to explicitly AVOID hitting break statement\n",
    "\n",
    "                if rdmol.GetNumAtoms() != 0:\n",
    "                    progress.update(STATUS, description=succ_msg)\n",
    "                    with (pdb_out_subdir / pdb_path.name).open('w') as outfile:\n",
    "                        outfile.write(pdb_block)\n",
    "                    worked = True\n",
    "                    break # skip external \"else\" clause if successful\n",
    "            \n",
    "                progress.update(STATUS, description=fail_msg)\n",
    "            else:\n",
    "                progress.update(STATUS, description='No remedy by shifting, defaulting to original file')\n",
    "                cop = copyfile(pdb_path, pdb_out_subdir / pdb_path.name)\n",
    "                worked = False\n",
    "\n",
    "            records[(poly_type, mol_name)] = worked\n",
    "            progress.advance(task2, advance=1)\n",
    "            progress.refresh()\n",
    "        \n",
    "        progress.advance(task1, advance=1)\n",
    "        progress.refresh()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curating available PDBs and monomer files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copying and organizing files, taking inventory of all pdbs and accompaying monomer files (if any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use_cleaned = False\n",
    "use_cleaned = True\n",
    "\n",
    "mono_dir = Path('polymer_examples/monomer_generation/json_files/')\n",
    "if use_cleaned:\n",
    "    pdb_dir = Path('cleaned_pdbs')\n",
    "    out_dir = Path('pdb_test_cleaned')\n",
    "else:\n",
    "    pdb_dir  = Path('polymer_examples/compatible_pdbs')\n",
    "    out_dir = Path('pdb_test')\n",
    "\n",
    "# defining output paths\n",
    "out_dir.mkdir(exist_ok=True)\n",
    "clear_dir(out_dir) # ensure directory begins empty\n",
    "\n",
    "pdb_out  = out_dir / 'pdbs'\n",
    "pdb_out.mkdir(exist_ok=True)\n",
    "\n",
    "mono_out = out_dir / 'monos'\n",
    "mono_out.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SQUARE_RE = re.compile(r's\\d+$')\n",
    "\n",
    "records = []\n",
    "pdb_subdirs_valid = [\n",
    "    pdb_subdir\n",
    "        for pdb_subdir in pdb_dir.iterdir()\n",
    "            if pdb_subdir.is_dir()\n",
    "]\n",
    "\n",
    "with Progress() as progress:\n",
    "    warnings.filterwarnings('ignore', category=DeprecationWarning) # doesn't actually seem to do anything about mbuild warnings\n",
    "    task1 = progress.add_task('Polymer Type', total=len(pdb_subdirs_valid))\n",
    "    task2 = progress.add_task('Molecule') # totals will vary by type\n",
    "\n",
    "    for pdb_subdir in pdb_subdirs_valid:\n",
    "        poly_type = pdb_subdir.name\n",
    "        progress.update(task1, description=f'Polymer Type : {poly_type}')\n",
    "\n",
    "        # generate copy directories for polymer type \n",
    "        pdb_out_subdir = pdb_out / poly_type\n",
    "        pdb_out_subdir.mkdir(exist_ok=True)\n",
    "\n",
    "        mono_out_subdir = mono_out / poly_type\n",
    "        mono_out_subdir.mkdir(exist_ok=True)\n",
    "\n",
    "        # locate all square-free PDBs present\n",
    "        pdb_paths_valid = [\n",
    "            pdb_path\n",
    "                for pdb_path in pdb_subdir.iterdir()\n",
    "                    if not re.search(SQUARE_RE, pdb_path.stem) # ignore squared patterns\n",
    "        ]\n",
    "\n",
    "        progress.reset(task2, total=len(pdb_paths_valid)) # clear progress on secondary bar, set length to new pdb count\n",
    "        for pdb_path in pdb_paths_valid:\n",
    "            mol_name = pdb_path.stem\n",
    "            progress.update(task2, description=f'Molecule : {mol_name}')\n",
    "            curr_pdb = copyfile(pdb_path, pdb_out_subdir / pdb_path.name)\n",
    "            \n",
    "            mono_path = mono_dir / f'{mol_name}.json'\n",
    "            if mono_path.exists():\n",
    "                curr_mono = copyfile(mono_path, mono_out_subdir / mono_path.name)\n",
    "            else:\n",
    "                mono_path = None\n",
    "\n",
    "            record = {\n",
    "                'Polymer Type' : poly_type,\n",
    "                'Molecule' : mol_name,\n",
    "                'PDB Path' : pdb_path,\n",
    "                'Monomer Path' : mono_path\n",
    "            }\n",
    "            records.append(record)\n",
    "            progress.advance(task2, advance=1)\n",
    "            progress.refresh()\n",
    "        \n",
    "        progress.advance(task1, advance=1)\n",
    "        progress.refresh()\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning) # doesn't actually seem to do anything about mbuild warnings\n",
    "\n",
    "# format dataframe into MultiIndex\n",
    "idx_cols = ['Polymer Type', 'Molecule']\n",
    "pdb_df = pd.DataFrame.from_records(records, index=idx_cols) # MultiIndex by type and mol\n",
    "pdb_df.sort_values(idx_cols, inplace=True) # sort by name within each polymer type\n",
    "\n",
    "# extract levels for reference, save inventory to csv\n",
    "poly_types, mols = pdb_df.index.levels\n",
    "pdb_df.to_csv(out_dir / 'pdb_inventory.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openmm.unit import nanosecond\n",
    "\n",
    "a = {'value' : 5, 'unit' : nanosecond}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Platform-based loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining PDB Loading tests for each platform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abstract base interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Optional\n",
    "from abc import ABC, abstractmethod, abstractclassmethod, abstractproperty\n",
    "from polysaccharide2.genutils.decorators.classmod import register_subclasses\n",
    "\n",
    "@register_subclasses(key_attr='name')\n",
    "class PDBLoadTester(ABC):\n",
    "    '''For defining framework-specific PDB reading tests'''\n",
    "    @abstractproperty\n",
    "    @classmethod\n",
    "    def name(cls) -> str:\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def load_pdb_obj(self, pdb_path : Path, mono_path : Path) -> Optional[Any]:\n",
    "        '''Implement the loading check for an individual PDB and monomer file here'''\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concrete implementations by framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from polysaccharide2.monomers.repr import MonomerGroup\n",
    "from openff.toolkit.utils.exceptions import UnassignedChemistryInPDBError\n",
    "\n",
    "\n",
    "class RDKitPDBLoadTester(PDBLoadTester):\n",
    "    name = 'RDKit'\n",
    "    \n",
    "    def load_pdb_obj(self, pdb_path: Path, mono_path: Path) -> Optional[Any]:\n",
    "        '''Load Mol from PDB file'''\n",
    "        rdmol = Chem.MolFromPDBFile(str(pdb_path)) \n",
    "        try:\n",
    "            if rdmol.GetNumAtoms() > 0:\n",
    "                return rdmol\n",
    "            return None\n",
    "        except AttributeError:\n",
    "            return None\n",
    "    \n",
    "class OpenMMPDBLoadTester(PDBLoadTester):\n",
    "    name = 'OpenMM'\n",
    "    \n",
    "    def load_pdb_obj(self, pdb_path: Path, mono_path: Path) -> Optional[Any]:\n",
    "        '''Return info about loadability'''\n",
    "        try:\n",
    "            return PDBFile(str(pdb_path))\n",
    "        except ValueError:\n",
    "            return None\n",
    "        \n",
    "class OpenFFPDBLoadTester(PDBLoadTester):\n",
    "    name = 'OpenFF'\n",
    "    \n",
    "    def load_pdb_obj(self, pdb_path: Path, mono_path: Path) -> Optional[Any]:\n",
    "        '''Return info about loadability'''\n",
    "        if mono_path is None:\n",
    "            return None\n",
    "        \n",
    "        mono_grp = MonomerGroup.from_file(mono_path)\n",
    "        try:\n",
    "            offtop = Topology.from_pdb(str(pdb_path), _custom_substructures=mono_grp.monomers)\n",
    "            return offtop\n",
    "        except UnassignedChemistryInPDBError:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looping over all available PDBs and testing by framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadable_dict = {}\n",
    "pdb_obj_dict  = {}\n",
    "\n",
    "with Progress() as progress:\n",
    "    warnings.filterwarnings('ignore', category=DeprecationWarning) # doesn't actually seem to do anything about mbuild warnings\n",
    "    task1 = progress.add_task('Polymer Type', total=len(poly_types))\n",
    "    task2 = progress.add_task('Molecule')\n",
    "    task3 = progress.add_task('Framework', total=len(PDBLoadTester.subclass_registry))\n",
    "\n",
    "    for poly_type, ptype_df in pdb_df.groupby(level=0):\n",
    "        progress.update(task1, description=f'Polymer Type : {poly_type}')\n",
    "        progress.reset(task2, total=len(ptype_df))\n",
    "        \n",
    "        for mol_name, mol_paths in ptype_df.droplevel(0).iterrows():\n",
    "            progress.update(task2, description=f'Molecule : {mol_name}')\n",
    "            pdb_path  = mol_paths.loc['PDB Path']\n",
    "            mono_path = mol_paths.loc['Monomer Path']\n",
    "            \n",
    "            progress.reset(task3)\n",
    "            fw_pdb_objs = {}\n",
    "            fw_loadable = {}\n",
    "            for framework, PDBLoadClass in PDBLoadTester.subclass_registry.items():\n",
    "                progress.update(task3, description=f'Framework : {framework}')\n",
    "                pdb_loader = PDBLoadClass() # instantiate generic class\n",
    "                pdb_obj = pdb_loader.load_pdb_obj(pdb_path, mono_path)\n",
    "\n",
    "                fw_pdb_objs[f'{framework} PDB Object'] = pdb_obj\n",
    "                fw_loadable[f'{framework} Loadable?' ] = bool(pdb_obj is not None)\n",
    "                progress.advance(task3)\n",
    "                progress.refresh()\n",
    "\n",
    "            pdb_obj_dict[ (poly_type, mol_name)] = fw_pdb_objs\n",
    "            loadable_dict[(poly_type, mol_name)] = fw_loadable\n",
    "            progress.advance(task2)\n",
    "            progress.refresh()\n",
    "\n",
    "        progress.advance(task1)\n",
    "        progress.refresh()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating DataFrames for tabular reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Booleans, whether objects are loadable\n",
    "loadable_df = pd.DataFrame(loadable_dict).transpose()\n",
    "loadable_df.index.names = idx_cols\n",
    "loadable_df = pd.concat([pdb_df, loadable_df], axis=1)\n",
    "\n",
    "loadable_df.to_csv(out_dir / 'pdbs_loadable.csv')\n",
    "\n",
    "# The actual PDB-objects by platform (including NoneType)\n",
    "pdb_obj_df = pd.DataFrame(pdb_obj_dict).transpose()\n",
    "pdb_obj_df.index.names = idx_cols\n",
    "pdb_obj_df = pd.concat([pdb_df, pdb_obj_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openff-pdb-pr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
