{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "916a7fa1d32c4f7395d0f221768654cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[13:53:24] WARNING: not removing hydrogen atom with dummy atom neighbors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "├───decoder\n",
      "├───encoder\n",
      "├───scanner\n",
      "└───tool\n"
     ]
    }
   ],
   "source": [
    "import polymerist as ps\n",
    "from polymerist import genutils, polymerist, duration\n",
    "from polymerist.genutils import bits, typetools, importutils\n",
    "\n",
    "import json, math\n",
    "import pkgutil, importlib\n",
    "\n",
    "print(importutils.module_hierarchy(json))\n",
    "\n",
    "from anytree import RenderTree, Node, AsciiStyle, ContStyle, ContRoundStyle, DoubleStyle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying out `anytree`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from anytree import Node\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def file_tree_from_path(path : Path, max_depth : Optional[int]=None, _curr_depth : int=0) -> Node:\n",
    "    '''Compiled a file/directory tree from a path\n",
    "    If recursive=True, will expand each subdirectory node into its own directory subtree'''\n",
    "    path_node = Node(path.name, path=path, is_dir=path.is_dir(), is_file=path.is_file())\n",
    "    if path.is_dir() and ( # recursively add subnodes IFF\n",
    "            (max_depth is None)             # 1) no depth limit is set, or\n",
    "            or (_curr_depth < max_depth)    # 2) a limit IS set, but hasn't been reached yet\n",
    "        ): \n",
    "        for subpath in path.iterdir():\n",
    "            subpath_node = file_tree_from_path(subpath, max_depth=max_depth, _curr_depth=_curr_depth+1)\n",
    "            subpath_node.parent = path_node\n",
    "\n",
    "    return path_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<function pkgutil.resolve_name(name)>, <function inspect.getmodulename(path)>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import inspect\n",
    "\n",
    "pkgutil.resolve_name, inspect.getmodulename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import ModuleType\n",
    "from typing import Iterable, Optional, TypeAlias, Union\n",
    "\n",
    "from importlib.machinery import SourceFileLoader, FileFinder\n",
    "import pkgutil\n",
    "import importlib, importlib.machinery\n",
    "\n",
    "from pathlib import Path\n",
    "from anytree import Node\n",
    "\n",
    "\n",
    "# EXTRACTING INFO FROM A SINGLE IMPORTED MODULE\n",
    "def flexible_module_pass(module : Union[str, Path, ModuleType]) -> ModuleType:\n",
    "    '''Flexible interface for supplying a ModuleType object as an argument\n",
    "    Allows for passing a name (either module name or string path), Path location, or a module proper'''\n",
    "    if isinstance(module, ModuleType):\n",
    "        return module\n",
    "    elif isinstance(module, str):\n",
    "        pass\n",
    "    elif isinstance(module, Path):\n",
    "        pass\n",
    "    else:\n",
    "        raise TypeError(f'Cannot interpret object of type \"{type(module).__name__}\" as a module')\n",
    "\n",
    "def is_package(module : Union[str, ModuleType]) -> bool:\n",
    "    '''Check whether a Python module is a package (i.e. contains other importable modules within itself)'''\n",
    "    # module_spec = getattr(module, '__spec__', None) # this doesn't work when a string is passed in\n",
    "    module_spec = importlib.util.find_spec(module.__name__)\n",
    "    if module_spec is None:\n",
    "        raise ValueError(f'No ModuleSpec found for {module}')\n",
    "\n",
    "    module_loader = module_spec.loader\n",
    "    # module_loader = pkgutil.get_loader(module) # NOTE: while more compact than above, this function is slated for deprecation\n",
    "    if module_loader is None:\n",
    "        raise ValueError(f'No SourcefileLoader found for {module}')\n",
    "\n",
    "    return module_loader.is_package(module.__name__)\n",
    "\n",
    "# TODO : find way to get depth of submodule in toplevel (\"number of dots\" before standalone name)\n",
    "def relative_module_name(module : ModuleType, relative_to : Optional[ModuleType]=None, remove_leading_dot : bool=True) -> str:\n",
    "    '''Gets the name of a module relative to another (presumably toplevel) module\n",
    "    If the given module is not in the path of the toplevel module, will simply return as module.__name__'''\n",
    "    rel_mod_name = module.__name__\n",
    "    if relative_to is not None:\n",
    "        toplevel_prefix = relative_to.__name__\n",
    "        if remove_leading_dot:\n",
    "            toplevel_prefix += '.' # append dot to prefix to remove it later\n",
    "        rel_mod_name = rel_mod_name.removeprefix(toplevel_prefix)\n",
    "\n",
    "    return rel_mod_name\n",
    "\n",
    "\n",
    "# COMPILING MODULE TREES FOR FULL PACKAGES\n",
    "def module_tree(module : ModuleType, blacklist : Optional[Iterable[str]]=None, relative_to : Optional[ModuleType]=None, max_depth : Optional[int]=None, _curr_depth : int=0) -> Optional[Node]:\n",
    "    '''Create a tree for a module and all its submodules, to a set depth and with optional blacklisting by module name'''\n",
    "    if blacklist is None:\n",
    "        blacklist = []\n",
    "\n",
    "    # TODO: figure out way to get loader (or FileFinder?) for toplevel\n",
    "    module_is_pkg = is_package(module)\n",
    "    module_name = relative_module_name(module, relative_to=relative_to, remove_leading_dot=True)\n",
    "\n",
    "    module_node = Node(module_name, module=module, module_is_pkg=module_is_pkg)\n",
    "    if module_is_pkg and ( # recursively add subnodes IFF\n",
    "            (max_depth is None)             # 1) no depth limit is set, or\n",
    "            or (_curr_depth < max_depth)    # 2) a limit IS set, but hasn't been reached yet\n",
    "        ):\n",
    "        for (submodule_loader, submodule_name, sub_is_pkg) in pkgutil.iter_modules(module.__path__):\n",
    "            if submodule_name not in blacklist: # TOSELF: also worth checking the full __name__? (requires importing a potentially blacklisted module which isn't great)\n",
    "                submodule = importlib.import_module(f'.{submodule_name}', package=module.__package__)\n",
    "                submodule_node = module_tree(submodule, blacklist=blacklist, relative_to=module, max_depth=max_depth, _curr_depth=_curr_depth+1)\n",
    "                submodule_node.parent = module_node\n",
    "\n",
    "    return module_node\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 14\u001b[0m\n\u001b[1;32m      2\u001b[0m mods \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m      3\u001b[0m     ps,\n\u001b[1;32m      4\u001b[0m     polymerist, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     math,\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m mods:\n\u001b[0;32m---> 14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(mod\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, is_package(mod), \u001b[43m__is_package_deprecated\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mgetattr\u001b[39m(mod, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__file__\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m), \u001b[38;5;28mgetattr\u001b[39m(mod, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__path__\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m     16\u001b[0m     mspec \u001b[38;5;241m=\u001b[39m mod\u001b[38;5;241m.\u001b[39m__spec__\n",
      "Cell \u001b[0;32mIn[4], line 45\u001b[0m, in \u001b[0;36m__is_package_deprecated\u001b[0;34m(module)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__is_package_deprecated\u001b[39m(module : ModuleType) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m     43\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''NOTE: this implementation is !!SLATED FOR DEPRECATION!! and is only kept here for illustrative purposes\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;124;03m    Check whether a Python module is a package (i.e. contains other importable modules within itself)'''\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloader\u001b[49m\u001b[38;5;241m.\u001b[39mis_package(module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'loader' is not defined"
     ]
    }
   ],
   "source": [
    "import json, math\n",
    "mods = (\n",
    "    ps,\n",
    "    polymerist, \n",
    "    genutils,\n",
    "    duration,\n",
    "    bits,\n",
    "    typetools,\n",
    "    json,\n",
    "    math,\n",
    ")\n",
    "\n",
    "for mod in mods:\n",
    "    print(mod.__name__, is_package(mod), __is_package_deprecated(mod))\n",
    "    print('\\t', getattr(mod, '__file__', None), getattr(mod, '__path__', None))\n",
    "    mspec = mod.__spec__\n",
    "    print('\\t', mspec.origin, mspec.parent, mspec.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_module_name(typetools, relative_to=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from anytree import RenderTree, Node, AsciiStyle, ContStyle, ContRoundStyle, DoubleStyle\n",
    "\n",
    "\n",
    "mt = module_tree(genutils, max_depth=None, relative_to=ps)\n",
    "rt = RenderTree(mt)\n",
    "print(rt.by_attr('name'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "main_path = Path('cleaned_pdbs')\n",
    "filetree = file_tree_from_path(main_path, max_depth=None)\n",
    "\n",
    "rt = RenderTree(filetree, style=ContRoundStyle())\n",
    "print(rt.by_attr('name'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = []\n",
    "for n in anytree.search.findall_by_attr(filetree, value=True, name='is_dir'):\n",
    "    print(n)\n",
    "    search.append(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(RenderTree(search[0]).by_attr('name'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Development of new features for polymerist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Developing monomer graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from rdkit import Chem\n",
    "\n",
    "import mbuild\n",
    "from mbuild.compound import Compound\n",
    "from mbuild.conversion import load, load_smiles, from_rdkit, to_smiles, to_pybel\n",
    "from mbuild.lib.recipes.polymer import Polymer\n",
    "\n",
    "comp = mbuild.Compound()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String/graph translation (SMILES-like)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from polymerist.polymers.monographs import MonomerGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openff.interchange.drivers import gromacs\n",
    "from openff.interchange import Interchange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = f'<tests[-2]>.<tests[-2]>'\n",
    "tests = [\n",
    "    '[a]<-1>[A](<2-3>[Bee]<2=5>[C]<5=2>[Bee]<3-6>[Bee])(<2-3>[Bee](<3-6>[Bee])<3->[a])<->[A]<2-2>[Bee]<3-6>[Bee]',\n",
    "    '[A]<1-2>[B]<6=5>[C](<4=3>[E])<#>[D]',\n",
    "]\n",
    "seq = [0, 1]\n",
    "test = '.'.join(tests[i] for i in seq)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tail = '[tail]<2-0>' * 10 + '[tail_end]'\n",
    "lipid = f'[A3](<4-3>[A2]{tail})(<4-3>[A2]{tail})<2-0>{tail}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1 = '<->[A3](<=1>[B0])<2=2>[B0]'\n",
    "b2 = '<->[B2]<3->[A3](<=1>[B0])<-1>[B2]'\n",
    "b3 = '[A3]<-1>[B(<-2>[B2])<->[B2]'\n",
    "branched = f'[A3]({b2}{b1})({b2}{b2}{b1})({b2}({b1}){b2}{b1})'\n",
    "branched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from polymerist.polymers.monomers import specification\n",
    "from polymerist.rdutils.rdkdraw import set_rdkdraw_size\n",
    "from rdkit import Chem\n",
    "\n",
    "set_rdkdraw_size(300, 3/2)\n",
    "\n",
    "smi = '[3*]-c1ccc(C=*)cc1C(=O)N[1*]'\n",
    "exp_smi = specification.expanded_SMILES(smi, assign_map_nums=False)\n",
    "mol = Chem.MolFromSmiles(smi, sanitize=False)\n",
    "display(mol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targ_smidge = test\n",
    "targ_smidge = lipid\n",
    "targ_smidge = branched\n",
    "\n",
    "G = MonomerGraph.from_SMIDGE(targ_smidge)\n",
    "G.visualize(label_monomers=True, label_bonds=True, font_size=10, font_color='black', pos=nx.spring_layout(G))#nx.kamada_kawai_layout(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{i : 5*v for i, v in nx.spring_layout(G).items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep = G.to_SMIDGE(start_node_idxs=6)\n",
    "H = MonomerGraph.from_SMIDGE(rep)\n",
    "H.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Alphabet\" of monomer fragment chemical information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import ascii_uppercase \n",
    "from polymerist.polymers.monomers import MonomerGroup\n",
    "from polymerist.rdutils.bonding.portlib import get_ports\n",
    "from polymerist.rdutils.labeling.molwise import clear_atom_map_nums\n",
    "\n",
    "\n",
    "parent_monomers = {\n",
    "    'ethane-1,2-diol' : 'OCCO',\n",
    "    'furan-2,5-dicarboxylic acid' : 'O=C(O)c1ccc(C(=O)O)o1',\n",
    "}\n",
    "monomer_aliases = {\n",
    "    mononame : lett*3\n",
    "        for mononame, lett in zip(parent_monomers.keys(), ascii_uppercase)\n",
    "}\n",
    "\n",
    "monogrp = MonomerGroup.from_file('poly(ethane-1,2-diol-co-furan-2,5-dicarboxylic acid).json')\n",
    "moldict, monosmiles = {}, {}\n",
    "for mononame, rdmol in monogrp.iter_rdmols():\n",
    "    for i, port in enumerate(get_ports(rdmol)):\n",
    "        rdmol.GetAtomWithIdx(port.linker.GetIdx()).SetIsotope(i)\n",
    "\n",
    "    print(mononame)\n",
    "    display(rdmol)\n",
    "    moldict[   mononame] = rdmol\n",
    "    monosmiles[mononame] = Chem.MolToSmiles(clear_atom_map_nums(rdmol))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining monomer information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, ClassVar\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "\n",
    "from polymerist.genutils.fileutils.jsonio.jsonify import make_jsonifiable, dataclass_serializer_factory\n",
    "from polymerist.genutils.fileutils.jsonio.serialize import JSONSerializable, TypeSerializer\n",
    "from polymerist.rdutils.bonding.portlib import get_num_linkers, get_num_ports\n",
    "from polymerist.polymers.monomers.specification import expanded_SMILES, compliant_mol_SMARTS\n",
    "\n",
    "\n",
    "@make_jsonifiable\n",
    "@dataclass\n",
    "class MonomerFragmentInfo:\n",
    "    '''Naming and in-line chemical encodings for a monomer unit within a polymer chain'''\n",
    "    name   : str\n",
    "    smiles : str\n",
    "    exp_smiles : Optional[str] = field(default=None, init=False, repr=False)\n",
    "    smarts     : Optional[str] = field(default=None)\n",
    "    category   : Optional[str] = field(default=None)\n",
    "\n",
    "    n_atoms       : int = field(init=False)\n",
    "    functionality : int = field(init=False)\n",
    "    contribution  : int = field(init=False)\n",
    "\n",
    "    FOO : ClassVar[str] = 'extra bits'\n",
    "\n",
    "    def __post_init__(self) -> None:\n",
    "        self.exp_smiles = expanded_SMILES(self.smiles, assign_map_nums=True)\n",
    "        if self.smarts is None:\n",
    "            self.smarts = compliant_mol_SMARTS(self.exp_smiles)\n",
    "\n",
    "        tempmol = self.rdmol\n",
    "        self.n_atoms = tempmol.GetNumAtoms()\n",
    "        self.functionality = get_num_ports(tempmol) # get_num_linkers(tempmol) \n",
    "        self.contribution = self.n_atoms - self.functionality\n",
    "\n",
    "    @property\n",
    "    def rdmol(self) -> Chem.Mol:\n",
    "        return Chem.MolFromSmiles(self.smiles, sanitize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from polymerist.polymers.monomers import specification\n",
    "\n",
    "mono_infos = {}\n",
    "for mononame, smiles in monosmiles.items():\n",
    "    parent_mononame = mononame.split('_')[0]\n",
    "    parent_smiles = parent_monomers[parent_mononame]\n",
    "    parent_alias  = monomer_aliases[parent_mononame]\n",
    "\n",
    "    mono_info = MonomerFragmentInfo(\n",
    "        name=mononame,\n",
    "        smiles=smiles,\n",
    "        # smarts=specification.compliant_mol_SMARTS(smiles),\n",
    "        category=parent_smiles,\n",
    "    )\n",
    "    alias = parent_alias.lower() if (mono_info.functionality == 1) else parent_alias.upper()\n",
    "    mono_infos[alias] = mono_info\n",
    "mono_infos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining polymer composition class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum, StrEnum, auto\n",
    "\n",
    "from polymerist.genutils.fileutils.jsonio.serialize import JSONSerializable, TypeSerializer, MultiTypeSerializer\n",
    "from polymerist.genutils.fileutils.jsonio.jsonify import make_jsonifiable, JSONifiable\n",
    "from polymerist.polymers.monographs import MonomerGraph, MonomerGraphSerializer\n",
    "from polymerist.rdutils.bonding.portlib import get_num_linkers, get_ports\n",
    "\n",
    "\n",
    "MONOMER_CHARS = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789'\n",
    "class MonomerNeighborMismatch(Enum):\n",
    "    '''For annotating the various ways in which a piece of monomer information in a monomer alphabet does not match a monomer graph'''\n",
    "    NONE = 0\n",
    "    COUNT = auto()\n",
    "    BONDTYPE = auto()\n",
    "    NO_FLAVOR = auto()\n",
    "    DIFF_FLAVOR = auto()\n",
    "    NOT_NEIGHBORS = auto()\n",
    "\n",
    "\n",
    "@make_jsonifiable(type_serializer=MultiTypeSerializer(MonomerGraphSerializer, MonomerFragmentInfo.serializer))\n",
    "@dataclass\n",
    "class PolymerStructure:\n",
    "    '''Encodes a multi-scale structural representation of a polymer topology'''\n",
    "    mono_alphabet : dict[str, MonomerFragmentInfo] \n",
    "    monograph : MonomerGraph\n",
    "\n",
    "    single_char_mononames : dict[str, str] = field(default_factory=dict, init=False) \n",
    "\n",
    "    def __post_init__(self) -> None:\n",
    "        '''Post-process init attributes'''\n",
    "        self.single_char_mononames = { # remapping from the assigned monomers names to single characters for mbuild compatibility\n",
    "            mononame : remap_char\n",
    "                for (mononame, remap_char) in zip(self.mono_alphabet.keys(), MONOMER_CHARS)\n",
    "        }\n",
    "\n",
    "        self.validate_monoinfo_is_compatible() # will raise targetted exceptions if incompatible\n",
    "        self.assign_monoinfo_to_monograph()\n",
    "\n",
    "    @property\n",
    "    def node_info_map(self) -> dict[int, MonomerFragmentInfo]:\n",
    "        '''Map from node indices to relevant monomer information'''\n",
    "        return {\n",
    "            node_id : self.mono_alphabet[alias]\n",
    "                for node_id, alias in nx.get_node_attributes(self.monograph, self.monograph.MONOMER_NAME_ATTR).items()\n",
    "        }\n",
    "    \n",
    "    @property\n",
    "    def pdb_substructures(self) -> dict[str, list[str]]:\n",
    "        '''Substructure dict formatted for the OpenFF Topology.from_pdb RDKit wrapper hook'''\n",
    "        return {\n",
    "            monoinfo.name : [mono_info.smarts]\n",
    "                for monoinfo in self.mono_alphabet.values()\n",
    "        }\n",
    "    \n",
    "    @property\n",
    "    def num_atoms(self) -> int:\n",
    "        '''Total number of atoms in the topology specified'''\n",
    "        return sum(nx.get_node_attributes(self.monograph, 'contribution').values())\n",
    "\n",
    "    # validation\n",
    "    def monoalpha_surjective_to_monograph(self) -> bool:\n",
    "        '''Check whether the monomer alphabet covers all monomer types defined in the Graph'''\n",
    "        return self.monograph.unique_monomer_names.issubset(set(self.mono_alphabet.keys()))\n",
    "\n",
    "    def monoalpha_neighbors_are_valid(self) -> tuple[bool, int, MonomerNeighborMismatch]:\n",
    "        '''Determine whether and why adjacent monomers in the monomer graph do (or don't) have compatible chemical info'''\n",
    "        for node_idx, neighbor_dict in self.monograph.adj.items():\n",
    "            # 1) check that the number of neighbors in the graph matches the number of intermonomer bonding sites given chemically\n",
    "            neighbor_dict = dict(neighbor_dict) # convert from networkx object to vanilla dict\n",
    "            degree = len(neighbor_dict) # self.monograph.degree[node_idx]\n",
    "            if (degree != self.node_info_map[node_idx].functionality):\n",
    "                return False, node_idx, MonomerNeighborMismatch.COUNT\n",
    "            \n",
    "            # 2) check that all reported neighbor nodes are actually adjacent in the graph\n",
    "            found_ports = set()\n",
    "            for i, flavor in self.monograph.get_flavor_dict(node_idx).items():\n",
    "                if i not in neighbor_dict:\n",
    "                    return False, node_idx, MonomerNeighborMismatch.NOT_NEIGHBORS\n",
    "                \n",
    "                nb_bond_info = neighbor_dict.pop(i)\n",
    "                found_ports.add( (flavor, nb_bond_info[self.monograph.BONDTYPE_ATTR]) )\n",
    "\n",
    "            # 3) check that every neighbors has been provided a flavor\n",
    "            if neighbor_dict:\n",
    "                return False, node_idx, MonomerNeighborMismatch.NO_FLAVOR # at least one of the neighbors must nnot have had a flavor provided\n",
    "\n",
    "            # 4) check that the provided flavors match those chemically specified\n",
    "            monoinfo = self.mono_alphabet[self.monograph.get_monomer_name(node_idx)]\n",
    "            portinfo = set(\n",
    "                (port.flavor, port.bond.GetBondType())\n",
    "                    for port in get_ports(monoinfo.rdmol)\n",
    "            )\n",
    "            if (portinfo != found_ports):\n",
    "                return False, node_idx, MonomerNeighborMismatch.DIFF_FLAVOR\n",
    "        else:\n",
    "            return True, -1, MonomerNeighborMismatch.NONE\n",
    "        \n",
    "    def validate_monoinfo_is_compatible(self) -> None:\n",
    "        if not self.monoalpha_surjective_to_monograph():\n",
    "            raise ValueError('Provided monomer alphabet does not cover all monomers in the corresponding monomer graph')\n",
    "        \n",
    "        nb_match, mismatch_idx, reason = self.monoalpha_neighbors_are_valid()\n",
    "        if not nb_match:\n",
    "            raise ValueError(f'Graph node {mismatch_idx} (designation \"{self.monograph.get_monomer_name(mismatch_idx)}\") mismatched (reason : {reason.name})')\n",
    "    \n",
    "    def assign_monoinfo_to_monograph(self) -> None:\n",
    "        '''Map the chemical info for each unique monomer onto corresponding monomer nodes in the monomer graph'''\n",
    "        node_info_map = {\n",
    "            node_idx : self.mono_alphabet[self.monograph.monomer_name(node_idx)].__dict__\n",
    "                for node_idx in self.monograph.nodes\n",
    "        }\n",
    "        nx.set_node_attributes(self.monograph, node_info_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from polymerist.genutils.textual import delimiters\n",
    "from polymerist.polymers.monographs import MonomerGraph\n",
    "\n",
    "smidge = 'aBABABABa'\n",
    "# smidge = '{2-3}'.join(smidge)\n",
    "# smidge = '{0-1}'.join(smidge)\n",
    "smidge = '<0-1>'.join(smidge[:-1]) + '<0-0>' + smidge[-1]\n",
    "smidge = delimiters.square_brackets_around_letters(smidge)\n",
    "smidge = ''.join(3*c if c.isalpha() else c for c in smidge)\n",
    "print(smidge)\n",
    "\n",
    "monograph = MonomerGraph.from_smidge(smidge)\n",
    "monograph.draw()\n",
    "\n",
    "poly = PolymerStructure(\n",
    "    mono_alphabet=mono_infos,\n",
    "    monograph=monograph\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing JSON I/O\n",
    "poly.to_file('test.json')\n",
    "poly2 = PolymerStructure.from_file('test.json')\n",
    "poly2.monograph.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mbuild.lib.recipes import Polymer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Developing mbuild coordinate generator hook for linear polymer graphs  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly.monograph.is_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in poly.monograph.termini:\n",
    "    print(poly.monograph.nodes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from polymerist.genutils.textual.strsearch import shortest_repeating_substring\n",
    "\n",
    "\n",
    "terms = list(monograph.termini)\n",
    "assert(len(terms) == 2)\n",
    "head_node = terms[0]\n",
    "\n",
    "seq = ''\n",
    "for i in nx.dfs_preorder_nodes(monograph, source=head_node):\n",
    "    if i not in terms:\n",
    "        mononame = monograph.nodes[i][monograph.MONOMER_NAME_ATTR]\n",
    "        seq += poly.single_char_mononames[mononame]\n",
    "min_seq = shortest_repeating_substring(seq)\n",
    "seq, min_seq, seq.count(min_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from polymerist.rdutils.bonding.portlib import Port\n",
    "from polymerist.rdutils.bonding.substitution import saturate_ports\n",
    "\n",
    "Port.bondable_flavors.reset()\n",
    "Port.bondable_flavors.insert((0,2))\n",
    "Port.bondable_flavors.insert((1,2))\n",
    "\n",
    "rm = mono_info.rdmol\n",
    "newmol = saturate_ports(rm, cap=Chem.MolFromSmiles('*-[2H]', sanitize=False), flavor_to_saturate=0)\n",
    "display(newmol)\n",
    "for atom in newmol.GetAtoms():\n",
    "    print(atom.GetIdx(), atom.GetSymbol(), atom.GetIsotope())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from polymerist.rdutils.bonding.substitution import hydrogenate_rdmol_ports\n",
    "from mbuild.conversion import from_rdkit\n",
    "from polymerist.polymers.building import mbmol_to_openmm_pdb\n",
    "\n",
    "\n",
    "prot_mol = hydrogenate_rdmol_ports(mono_info.rdmol)\n",
    "Chem.SanitizeMol(prot_mol, sanitizeOps=specification.SANITIZE_AS_KEKULE)\n",
    "mbmol = from_rdkit(prot_mol)\n",
    "mbmol_to_openmm_pdb('test.pdb', mbmol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playing with rich progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich.progress import track, Progress\n",
    "from time import sleep\n",
    "\n",
    "with Progress() as progress:\n",
    "\n",
    "    task1 = progress.add_task(\"[red]Downloading...\", total=1000)\n",
    "    task2 = progress.add_task(\"[green]Processing...\", total=1000)\n",
    "    task3 = progress.add_task(\"[cyan]Cooking...\", total=1000)\n",
    "\n",
    "    while not progress.finished:\n",
    "        progress.update(task1, advance=0.5)\n",
    "        progress.update(task2, advance=0.3)\n",
    "        progress.update(task3, advance=0.9)\n",
    "        sleep(0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "from rich.progress import (\n",
    "    BarColumn,\n",
    "    Progress,\n",
    "    SpinnerColumn,\n",
    "    TaskProgressColumn,\n",
    "    TimeElapsedColumn,\n",
    "    TimeRemainingColumn,\n",
    ")\n",
    "\n",
    "def process(chunks):\n",
    "    for chunk in chunks:\n",
    "        time.sleep(0.1)\n",
    "        yield chunk\n",
    "\n",
    "chunks = [random.randint(1,20) for _ in range(100)]\n",
    "\n",
    "progress_columns = (\n",
    "    SpinnerColumn(),\n",
    "    \"[progress.description]{task.description}\",\n",
    "    BarColumn(),\n",
    "    TaskProgressColumn(),\n",
    "    \"Elapsed:\",\n",
    "    TimeElapsedColumn(),\n",
    "    \"Remaining:\",\n",
    "    TimeRemainingColumn(),\n",
    ")\n",
    "\n",
    "with Progress(*progress_columns) as progress_bar:\n",
    "    task = progress_bar.add_task(\"[blue]Downloading...\", total=sum(chunks))\n",
    "    for chunk in process(chunks):\n",
    "        progress_bar.update(task, advance=chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "from rich.live import Live\n",
    "from rich.table import Table\n",
    "\n",
    "\n",
    "def generate_table() -> Table:\n",
    "    \"\"\"Make a new table.\"\"\"\n",
    "    table = Table()\n",
    "    table.add_column(\"ID\")\n",
    "    table.add_column(\"Value\")\n",
    "    table.add_column(\"Status\")\n",
    "\n",
    "    for row in range(random.randint(2, 6)):\n",
    "        value = random.random() * 100\n",
    "        table.add_row(\n",
    "            f\"{row}\", f\"{value:3.2f}\", \"[red]ERROR\" if value < 50 else \"[green]SUCCESS\"\n",
    "        )\n",
    "    return table\n",
    "\n",
    "\n",
    "with Live(generate_table(), refresh_per_second=4) as live:\n",
    "    for _ in range(40):\n",
    "        time.sleep(0.4)\n",
    "        live.update(generate_table())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from rich.console import Console, ConsoleOptions, RenderResult\n",
    "from rich.table import Table\n",
    "\n",
    "@dataclass\n",
    "class Student:\n",
    "    id: int\n",
    "    name: str\n",
    "    age: int\n",
    "    def __rich_console__(self, console: Console, options: ConsoleOptions) -> RenderResult:\n",
    "        yield f\"[b]Student:[/b] #{self.id}\"\n",
    "        my_table = Table(\"Attribute\", \"Value\")\n",
    "        my_table.add_row(\"name\", self.name)\n",
    "        my_table.add_row(\"age\", str(self.age))\n",
    "        yield my_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimenting with SDF files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benz = Chem.MolFromSmiles('C1ccccC=1')\n",
    "benz = Chem.AddHs(benz)\n",
    "benz.SetDoubleProp('stuff', 3.14)\n",
    "benz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block2k = Chem.MolToMolFile(benz, 'test_2k.sdf')\n",
    "block3k = Chem.MolToV3KMolFile(benz, 'test_3k.sdf')\n",
    "block2kforce = Chem.MolToMolFile(benz, 'test_2k_force.sdf', forceV3000=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Chem.SDWriter('test_sdw.sdf') as sdwriter:\n",
    "    sdwriter.SetForceV3000(True)\n",
    "    print(sdwriter.GetForceV3000())\n",
    "\n",
    "    sdwriter.write(benz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Chem.SDMolSupplier('sdf_testing/test_off_rd.sdf', sanitize=False) as suppl:\n",
    "    mols = [mol for mol in suppl]\n",
    "\n",
    "targ = mols[0]\n",
    "targ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "omol = Molecule.from_rdkit(benz)\n",
    "omol.generate_conformers(n_conformers=1)\n",
    "omol.visualize(backend='nglview')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing polymerist importability within environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from openff.toolkit import Molecule, Topology, ForceField"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polymerist as ps\n",
    "from polymerist.genutils import pyimports, importutils\n",
    "\n",
    "import pandas as pd\n",
    "print(importutils.module_hierarchy(ps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nglview\n",
    "\n",
    "print(nglview.__version__)\n",
    "nglview.demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from polymerist.polymers.monomers import specification\n",
    "from rdkit import Chem\n",
    "\n",
    "smi = 'CCO-c1ccccc1-N=C=C'\n",
    "mol1 = Chem.MolFromSmiles(smi)\n",
    "display(mol1)\n",
    "\n",
    "sma = specification.expanded_SMILES(smi, assign_map_nums=True)\n",
    "exp_sma = specification.compliant_mol_SMARTS(sma)\n",
    "mol2 = Chem.MolFromSmarts(sma)\n",
    "display(mol2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openff.toolkit import Molecule\n",
    "\n",
    "offmol = Molecule.from_smiles(smi)\n",
    "offmol.generate_conformers(n_conformers=1)\n",
    "offmol.visualize(backend='nglview')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamically reading all import statements in codebase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polymerist as ps\n",
    "from polymerist.genutils import pyimports, importutils\n",
    "\n",
    "print(importutils.module_hierarchy(ps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infos = pyimports.extract_imports_from_module(ps)\n",
    "\n",
    "df = pd.DataFrame.from_records([info.__dict__ for info in infos])\n",
    "df.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonrel = [info for info in infos if not info.is_relative and info.parent_module is None]\n",
    "len(nonrel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "imported_names = set(info.object_name for info in nonrel)\n",
    "imported_names\n",
    "\n",
    "registered_builtins = set(sys.builtin_module_names)\n",
    "registered_stdlibs = set(sys.stdlib_module_names)\n",
    "\n",
    "nb_imports = imported_names - registered_builtins - registered_stdlibs\n",
    "nb_imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Another thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "polymerist-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
